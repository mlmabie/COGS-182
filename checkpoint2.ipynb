{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW8_skeleton.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "pycharm-84c90525",
      "display_name": "PyCharm (kyso-zip_openai-gym-jupyter_948e7f705d0ffaeff9859b1208a44268)",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gym.envs.box2d import BipedalWalker\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WalkerAgent(BipedalWalker):\n",
        "    def step(self, action):\n",
        "        state, reward, done, o = super().step(action)\n",
        "        # Hull has angular velocitry, x.velocity, and y.velocity, each normalized by FPS.\n",
        "        # Leg 0 Joint 0 has an angle and speed, normalized by SPEED_HIP\n",
        "        # Leg 0 Joint 1 has angle+1, and speed normalized by SPEED_KNEE\n",
        "        # Leg 0 Contact is boolean.\n",
        "        # Leg 1 same as Leg 0.\n",
        "        for a in action:\n",
        "            total_torque += np.clip(np.abs(a), 0, 1)\n",
        "\n",
        "        features = np.array([\n",
        "                    self.hull.position[0], # 0 distance traveled\n",
        "                    np.abs(state[0]),      # 1 head stability\n",
        "                    np.abs(total_torque),  # 2 torque per step\n",
        "                    state[8] and state[13],# 3 legs up, jump \n",
        "\n",
        "                    np.abs(state[4]),      # 4 leg0 hip angle\n",
        "                    np.abs(state[5]),      # 5 leg0 hip speed\n",
        "                    np.abs(state[6]),      # 6 leg0 knee angle\n",
        "                    np.abs(state[7]),      # 7 leg0 knee speed\n",
        "\n",
        "                    np.abs(state[9]),      # 8 leg1 hip angle\n",
        "                    np.abs(state[10]),     # 9 leg1 hip speed\n",
        "                    np.abs(state[11]),     # 10 leg1 knee angle\n",
        "                    np.abs(state[12])      # 11 leg1 knee speed\n",
        "                    ])\n",
        "        return np.array(state), reward, features, done, o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we will sample the environment output for a few agent actions.\n",
        "def simulate(model, env, render_mode=False, num_episodes=5):\n",
        "    #reward_list = []\n",
        "    #t_list = []\n",
        "    max_episode_length = 3000\n",
        "    episodes_reward_sum = 0\n",
        "    episodes_feature_sum = (0,) * 12\n",
        "    total_reward = 0.0\n",
        "    total_features = (0,) * 12\n",
        "\n",
        "    for episode in range(num_episode):\n",
        "        #start_time = timer()\n",
        "        obs = env.reset()\n",
        "\n",
        "        if obs is None:\n",
        "            obs = np.zeros(model.input_size)\n",
        "\n",
        "        for t in range(max_episode_length):\n",
        "            if render_mode:\n",
        "                env.render(\"human\")\n",
        "\n",
        "            #action = model.get_action(obs, t=t, mean_mode=False)\n",
        "            action = model.get_action(obs)\n",
        "            prev_obs = obs\n",
        "            obs, reward, features, done, info = env.step(action)\n",
        "\n",
        "            if render_mode:\n",
        "                pass\n",
        "                #print(\"action\", action, \"step reward\", reward)\n",
        "                #print(\"step reward\", reward)\n",
        "            total_reward += reward\n",
        "            total_features = tuple(x + y for x,y in zip(total_features, features))\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        if render_mode:\n",
        "            print(\"reward\", total_reward, \"timesteps\", t)\n",
        "        #reward_list.append(total_reward)\n",
        "        #t_list.append(t)\n",
        "        #duration = timer() - start_time\n",
        "        #print(f\"DEBUG simulate duration: {duration / t}\")\n",
        "\n",
        "    total_features = tuple(x + y for x,y in zip(total_features, features))\n",
        "    total_features = tuple(x/t for x in total_features)\n",
        "\n",
        "    episodes_reward_sum += total_reward\n",
        "    episodes_feature_sum = tuple(x + y for x,y in zip(episodes_feature_sum, total_features))\n",
        "\n",
        "    episode_avg_reward = episodes_reward_sum / num_episode\n",
        "    episode_avg_features = tuple(x/num_episode for x in episodes_feature_sum)\n",
        "\n",
        "    #return reward_list, t_list\n",
        "    #print(\"MODEL: REWARD\", episode_avg_reward)\n",
        "    #print(\"MODEL: AVG FEATURES (orig, leg0, leg1)\", episode_avg_features)\n",
        "    #return tuple(reward_list), tuple(total_features)\n",
        "\n",
        "    #scores = {'AvgReward': episode_avg_reward, 'Distance',\n",
        "\n",
        "    scores = {\n",
        "            \"meanAvgReward\": episode_avg_reward,\n",
        "            \"meanDistance\": episode_avg_features[0],\n",
        "            \"meanHeadStability\": episode_avg_features[1],\n",
        "            \"meanTorquePerStep\": episode_avg_features[2],\n",
        "            \"meanJump\": episode_avg_features[3],\n",
        "            \"meanLeg0HipAngle\": episode_avg_features[4],\n",
        "            \"meanLeg0HipSpeed\": episode_avg_features[5],\n",
        "            \"meanLeg0KneeAngle\": episode_avg_features[6],\n",
        "            \"meanLeg0KneeSpeed\": episode_avg_features[7],\n",
        "            \"meanLeg1HipAngle\": episode_avg_features[8],\n",
        "            \"meanLeg1HipSpeed\": episode_avg_features[9],\n",
        "            \"meanLeg1KneeAngle\": episode_avg_features[10],\n",
        "            \"meanLeg1KneeSpeed\": episode_avg_features[11]\n",
        "    }\n",
        "\n",
        "    #return (episode_avg_reward,), tuple(episode_avg_features)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_env(seed=-1):\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        env = QDBipedalWalker()\n",
        "\n",
        "    if (seed >= 0):\n",
        "        env.seed(seed)\n",
        "\n",
        "    #print(\"environment details\")\n",
        "    #print(\"env.action_space\", env.action_space)\n",
        "    #print(\"high, low\", env.action_space.high, env.action_space.low)\n",
        "    #print(\"environment details\")\n",
        "    #print(\"env.observation_space\", env.observation_space)\n",
        "    #print(\"high, low\", env.observation_space.high, env.observation_space.low)\n",
        "    #assert False\n",
        "    return env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}